{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9d133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import diffusion_pde as dpde\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import Subset\n",
    "from torch.func import jvp\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9028efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 2.],\n",
      "        [1., 3.]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.ones(4).view(4, 1)\n",
    "a = torch.arange(4).view(4, 1)\n",
    "\n",
    "print(torch.cat([b, a], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_timeseries(\n",
    "    net,                # EDMWrapper (calls Unet inside)\n",
    "    device,             # device to run the sampler on  \n",
    "    sample_shape,       # (B, C, H, W) shape of samples\n",
    "    t_steps,            # array of time steps to sample over\n",
    "    loss_fn,            # loss function to compute gradients\n",
    "    loss_fn_kwargs,     # extra args to pass to loss function\n",
    "    extra_labels=None,  # (B, label_dim-1) extra conditioning your Unet expects aside from time conditioning\n",
    "    zeta_a=1.0,         # weight for obs_a loss\n",
    "    zeta_u=1.0,         # weight for obs_u loss\n",
    "    zeta_pde=1.0,      # weight for pde loss\n",
    "    num_steps=18,\n",
    "    sigma_min=0.002,\n",
    "    sigma_max=80.0,\n",
    "    rho=7.0,\n",
    "    S_churn=0.0,\n",
    "    S_min=0.0,\n",
    "    S_max=float('inf'),\n",
    "    S_noise=1.0,\n",
    "    generator=None,\n",
    "    debug=False,\n",
    "):\n",
    "    t_steps = torch.tensor(t_steps, dtype=torch.float32)\n",
    "\n",
    "    for i in range(t_steps.shape[0]):\n",
    "\n",
    "        labels = torch.full((sample_shape[0], 1), t_steps[i])\n",
    "        if extra_labels is not None:\n",
    "            labels = torch.cat([labels, extra_labels], dim=-1)\n",
    "\n",
    "        samples, losses = dpde.sampling.edm_sampler(\n",
    "            net=net,\n",
    "            device=device,\n",
    "            sample_shape=sample_shape,\n",
    "            loss_fn=loss_fn,\n",
    "            loss_fn_kwargs=loss_fn_kwargs,\n",
    "            labels=labels,\n",
    "            zeta_a=zeta_a,\n",
    "            zeta_u=zeta_u,\n",
    "            zeta_pde=zeta_pde,\n",
    "            num_steps=num_steps,\n",
    "            sigma_min=sigma_min,\n",
    "            sigma_max=sigma_max,\n",
    "            rho=rho,\n",
    "            S_churn=S_churn,\n",
    "            S_min=S_min,\n",
    "            S_max=S_max,\n",
    "            S_noise=S_noise,\n",
    "            generator=generator,\n",
    "            debug=debug,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyndiffenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
