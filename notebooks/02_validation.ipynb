{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9d133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import diffusion_pde as dpde\n",
    "from diffusion_pde.pdes import generate_heat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import Subset\n",
    "from torch.func import jvp\n",
    "\n",
    "from pathlib import Path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9028efaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"logt\"\n",
    "model_path = Path().cwd().parent / \"pretrained_models\" / f\"heat_{data_name}.pth\"\n",
    "data_path = Path().cwd().parent / \"data\" / f\"heat_{data_name}.hdf5\"\n",
    "model_path.exists(), data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21a095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape:  (200, 1, 64, 64)\n",
      "U shape:  (200, 1, 64, 64, 65)\n",
      "Labels shape:  (200, 1)\n",
      "t_steps shape:  (65,)\n",
      "Lx : 1.0\n",
      "Ly : 1.0\n",
      "S : 64\n",
      "T : 0.5\n",
      "alpha_logrange : [-2.  0.]\n",
      "description : 2D heat equation with linear Dirichlet BCs, data generated with sine-pseudospectral method with lifting. Time steps in log-scale.\n",
      "dx : 0.015873015873015872\n",
      "name : heat_logt\n",
      "num_test : 200\n",
      "num_train : 800\n",
      "steps : 64\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(data_path, \"r\") as f:\n",
    "    attrs = dict(f.attrs)\n",
    "    data_A = f[\"test/A\"][:]  # (N, 1, S, S)\n",
    "    data_U = f[\"test/U\"][:]  # (N, 1, S, S, steps+1)\n",
    "    data_labels = f[\"test/labels\"][:]  # (N,)\n",
    "    t_steps = f[\"t_steps\"][:]  # (steps+1,)\n",
    "print(\"A shape: \", data_A.shape)  # (N, 1, S, S)\n",
    "print(\"U shape: \", data_U.shape)  # (N, 1, S, S, steps+1)\n",
    "print(\"Labels shape: \", data_labels.shape)  # (N,)\n",
    "print(\"t_steps shape: \", t_steps.shape)  # (steps+1,)\n",
    "\n",
    "[print(k, \":\", v) for k, v in attrs.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817a4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = attrs[\"T\"]\n",
    "S = attrs[\"S\"]\n",
    "Lx = attrs[\"Lx\"]\n",
    "Ly = attrs[\"Ly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "112b2081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s204790/miniconda3/envs/dyndiffenv/lib/python3.11/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc9d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_SAMPLES = 50\n",
    "T_STEPS = 100\n",
    "SEED = 42\n",
    "\n",
    "t_steps = torch.linspace(0, T, T_STEPS + 1)\n",
    "dt = t_steps[1:] - t_steps[:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1eab47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m U, A, t_steps, labels = \u001b[43mgenerate_heat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mN\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_TEST_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mLx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mLy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mic_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEED\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dyndiffenv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dynamical-pde-diffusion/src/diffusion_pde/pdes/generate_heat.py:195\u001b[39m, in \u001b[36mgenerate_heat\u001b[39m\u001b[34m(N, B, S, steps, dt, Lx, Ly, alpha_logrange, device, dtype, ic_seed)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_heat\u001b[39m(\n\u001b[32m    182\u001b[39m         N: \u001b[38;5;28mint\u001b[39m,                 \u001b[38;5;66;03m# Total number of samples\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m         ic_seed: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,         \u001b[38;5;66;03m# random seed for IC generation (None = random each call\u001b[39;00m\n\u001b[32m    193\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     X, Y = \u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# (S,S)\u001b[39;00m\n\u001b[32m    196\u001b[39m     S_dst, lam2d = dirichlet_sine_basis(S, Lx, Ly, device=device, dtype=dtype)  \u001b[38;5;66;03m# (S,S), (S,S)\u001b[39;00m\n\u001b[32m    198\u001b[39m     U = torch.empty((N, \u001b[32m1\u001b[39m, S, S, steps+\u001b[32m1\u001b[39m), dtype=dtype)  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dynamical-pde-diffusion/src/diffusion_pde/pdes/generate_heat.py:17\u001b[39m, in \u001b[36mmake_grid\u001b[39m\u001b[34m(N, Lx, Ly, device, dtype)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_grid\u001b[39m(N: \u001b[38;5;28mint\u001b[39m = \u001b[32m64\u001b[39m, Lx: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m, Ly: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m, *, device=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     y = torch.linspace(\u001b[32m0.\u001b[39m, Ly, N, device=device, dtype=dtype)\n\u001b[32m     19\u001b[39m     Y, X = torch.meshgrid(y, x, indexing=\u001b[33m'\u001b[39m\u001b[33mij\u001b[39m\u001b[33m'\u001b[39m)   \u001b[38;5;66;03m# (N,N)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dyndiffenv/lib/python3.11/site-packages/torch/cuda/__init__.py:412\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    411\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    416\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "U, A, t_steps, labels = generate_heat(\n",
    "    N=NUM_TEST_SAMPLES,\n",
    "    B=50,\n",
    "    S=S,\n",
    "    steps=T_STEPS,\n",
    "    dt=dt,\n",
    "    Lx=Lx,\n",
    "    Ly=Ly,\n",
    "    device=\"cuda\",\n",
    "    ic_seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_timeseries(\n",
    "    data_test,          # test data shape: (N, C_in + C_out, H, W)\n",
    "    net,                # EDMWrapper (calls Unet inside)\n",
    "    device,             # device to run the sampler on  \n",
    "    sample_shape,       # (B, C_in + C_out, H, W) shape of samples\n",
    "    t_steps,            # array of time steps to sample over\n",
    "    loss_fn,            # loss function to compute gradients\n",
    "    loss_fn_kwargs,     # extra args to pass to loss function\n",
    "    extra_labels=None,  # (B, label_dim-1) extra conditioning your Unet expects aside from time conditioning\n",
    "    zeta_a=1.0,         # weight for obs_a loss\n",
    "    zeta_u=1.0,         # weight for obs_u loss\n",
    "    zeta_pde=1.0,      # weight for pde loss\n",
    "    num_steps=18,\n",
    "    sigma_min=0.002,\n",
    "    sigma_max=80.0,\n",
    "    rho=7.0,\n",
    "    S_churn=0.0,\n",
    "    S_min=0.0,\n",
    "    S_max=float('inf'),\n",
    "    S_noise=1.0,\n",
    "    generator=None,\n",
    "    debug=False,\n",
    "):  \n",
    "    errors = np.zeros((t_steps.shape[0], sample_shape[0]))\n",
    "    t_steps = torch.tensor(t_steps, dtype=torch.float32)\n",
    "\n",
    "    for i in range(t_steps.shape[0]):\n",
    "\n",
    "        labels = torch.full((sample_shape[0], 1), t_steps[i])\n",
    "        if extra_labels is not None:\n",
    "            labels = torch.cat([labels, extra_labels], dim=-1)\n",
    "\n",
    "        samples, _ = dpde.sampling.edm_sampler(\n",
    "            net=net,\n",
    "            device=device,\n",
    "            sample_shape=sample_shape,\n",
    "            loss_fn=loss_fn,\n",
    "            loss_fn_kwargs=loss_fn_kwargs,\n",
    "            labels=labels,\n",
    "            zeta_a=zeta_a,\n",
    "            zeta_u=zeta_u,\n",
    "            zeta_pde=zeta_pde,\n",
    "            num_steps=num_steps,\n",
    "            sigma_min=sigma_min,\n",
    "            sigma_max=sigma_max,\n",
    "            rho=rho,\n",
    "            S_churn=S_churn,\n",
    "            S_min=S_min,\n",
    "            S_max=S_max,\n",
    "            S_noise=S_noise,\n",
    "            generator=generator,\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "        errors[i, :] = torch.norm(samples - data_test[i, ...], dim=(1,2,3)).detach().cpu().numpy()\n",
    "\n",
    "    return errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyndiffenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
