{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import diffusion_pde as dpde\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wandb.apis.public.runs import Runs, Run\n",
    "from wandb.apis.public.artifacts import RunArtifacts\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from skopt import gp_minimize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44919a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "API = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd51c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_cfg = OmegaConf.load(\"../conf/train.yaml\").wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d42c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {}#{\"tags\": \"fine-tune\"}\n",
    "\n",
    "runs = Runs(\n",
    "    client=API.client,\n",
    "    entity=wandb_cfg.entity,\n",
    "    project=wandb_cfg.project,\n",
    "    filters=filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a50e1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - Run ID: hodjisac, Name: heat-logt/forward/unet-v2\n",
      "Index: 1 - Run ID: 8nb62ytp, Name: heat-logt/forward/unet-v2\n",
      "Index: 2 - Run ID: 4labp6a8, Name: heat-logt/joint/unet-v2\n",
      "Index: 3 - Run ID: lykjcqiu, Name: heat-logt/joint/unet-v2\n",
      "Index: 4 - Run ID: rot73q78, Name: heat-logt/joint/unet-v2/fine-tune\n",
      "Index: 5 - Run ID: 48vnbamd, Name: heat-logt/joint/unet-v2/fine-tune\n",
      "Index: 6 - Run ID: qxoyf4d4, Name: heat-logt/joint/unet-v2/fine-tune\n",
      "Index: 7 - Run ID: wu23ezqs, Name: heat-logt/joint/unet-v2/fine-tune\n",
      "Index: 8 - Run ID: orbatwtx, Name: heat-logt/joint/unet-v2/fine-tune\n",
      "Index: 9 - Run ID: u0316v5n, Name: heat-logt/joint/unet-v2/fine-tune\n",
      "Index: 10 - Run ID: wwx06zrf, Name: heat-logt/forward/unet-v2/fine-tune\n",
      "Index: 11 - Run ID: 3hh696qs, Name: heat-logt/forward/unet-v2/fine-tune\n"
     ]
    }
   ],
   "source": [
    "for i, run in enumerate(runs):\n",
    "    print(f\"Index: {i} - Run ID: {run.id}, Name: {run.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dcf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_compare = [3, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1574c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: heat_logt\n",
      "model: unet-v2\n",
      "method: joint\n"
     ]
    }
   ],
   "source": [
    "run_idx = 3\n",
    "run_cfg = OmegaConf.create(runs[run_idx].config)\n",
    "\n",
    "print(f\"dataset: {run_cfg.dataset.data.name}\")\n",
    "print(f\"model: {run_cfg.model.name}\")\n",
    "print(f\"method: {run_cfg.dataset.method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cc2cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'API' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model\u001b[39m(run: Run, api: wandb.Api = \u001b[43mAPI\u001b[49m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      2\u001b[39m     model_path = Path(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m../pretrained_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ema_model.pth\u001b[39m\u001b[33m\"\u001b[39m).resolve()\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(model_path):\n",
      "\u001b[31mNameError\u001b[39m: name 'API' is not defined"
     ]
    }
   ],
   "source": [
    "def get_model(run: Run, api: wandb.Api = API) -> str:\n",
    "    model_path = Path(f\"../pretrained_models/{run.id}/model.pth\").resolve()\n",
    "    if not os.path.isfile(model_path):\n",
    "        arts = RunArtifacts(client=api.client, run=run)\n",
    "        _ = arts[0].download(root=f\"../pretrained_models/{run.id}/\")\n",
    "    return model_path\n",
    "    \n",
    "model_path = get_model(runs[run_idx])\n",
    "print(f\"Model path: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d2e2a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edm = dpde.utils.get_net_from_config(run_cfg)\n",
    "edm.load_state_dict(torch.load(model_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1c6eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(dpde.utils.get_repo_root() / \"data\" / \"heat_logt_validate.hdf5\", \"r\") as f:\n",
    "    data_A = f[\"A\"][:]\n",
    "    data_U = f[\"U\"][:]\n",
    "    data_labels = f[\"labels\"][:]\n",
    "    t_steps = f[\"t_steps\"][:]\n",
    "    attrs = dict(f.attrs)\n",
    "\n",
    "dx = attrs[\"dx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1898355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data attributes:\n",
      "  Lx: 1.0\n",
      "  Ly: 1.0\n",
      "  N: 200\n",
      "  S: 64\n",
      "  T: 0.5\n",
      "  alpha_logrange: [-2.5  0.5]\n",
      "  description: 2D heat equation with linear Dirichlet BCs, pseudospectral interior DST with lifting. log-spaced time.\n",
      "  dx: 0.015873015873015872\n",
      "  dy: 0.015873015873015872\n",
      "  name: heat_logt_validate\n",
      "  steps: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation data attributes:\")\n",
    "for attr in attrs:\n",
    "    print(f\"  {attr}: {attrs[attr]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9fbba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_a = 1 if run_cfg.dataset.method == \"joint\" else 0\n",
    "\n",
    "sample_shape = (16, 2 if ch_a else 1, 64, 64)\n",
    "\n",
    "#generator = torch.Generator().manual_seed(0)\n",
    "\n",
    "interior_a = 0.5\n",
    "interior_u = 0.0\n",
    "boundary_a = 0.5\n",
    "boundary_u = 0.0\n",
    "same_boundary = False\n",
    "\n",
    "\n",
    "def generate_masks(interior_a, interior_u, boundary_a, boundary_u, same_boundary):\n",
    "    boundary_obs_a = dpde.validation.random_boundary_mask(sample_shape[2], sample_shape[3], frac_obs=boundary_a)\n",
    "    if same_boundary:\n",
    "        boundary_obs_u = boundary_obs_a[:]\n",
    "    else:\n",
    "        boundary_obs_u = dpde.validation.random_boundary_mask(sample_shape[2], sample_shape[3], frac_obs=boundary_u)\n",
    "    interior_obs_a = dpde.validation.random_interior_mask(sample_shape[2], sample_shape[3], frac_obs=interior_a)\n",
    "    interior_obs_u = dpde.validation.random_interior_mask(sample_shape[2], sample_shape[3], frac_obs=interior_u)\n",
    "\n",
    "    mask_a = dpde.validation.combine_masks(boundary_obs_a, interior_obs_a)\n",
    "    mask_u = dpde.validation.combine_masks(boundary_obs_u, interior_obs_u)\n",
    "    return mask_a, mask_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02d32e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = dpde.sampling.EDMHeatSampler(\n",
    "    net=edm,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    sample_shape=(64, 64),\n",
    "    num_channels=2 if run_cfg.dataset.method == \"joint\" else 1,\n",
    "    num_steps=50,\n",
    "    sigma_min=0.002,\n",
    "    sigma_max=80.0,\n",
    "    rho=7.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8099ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampling_context:\n",
    "    def __init__(self, sampler: dpde.sampling.EDMHeatSampler):\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.prev_fp32_prec = torch.backends.cudnn.conv.fp32_precision\n",
    "        torch.backends.cudnn.conv.fp32_precision = 'tf32'\n",
    "        self.sampler.net.eval()\n",
    "        self.sampler.net.to(self.sampler.device)\n",
    "        #return self.sampler\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        torch.backends.cudnn.conv.fp32_precision = self.prev_fp32_prec\n",
    "        self.sampler.net.to(torch.device(\"cpu\"))\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ab3cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0 indices: [63 16 75 70 35  6 97 44 89 67 77 75 19 36 46 49  4 54 15 74]\n",
      "tf indices: [88 94 94 81 98 45 98 95 93 69 88 95 34 66 53 84 50 69 34 89]\n"
     ]
    }
   ],
   "source": [
    "NUM_TO_EVAL = 20\n",
    "T = t_steps.shape[0]\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "sample_idxs = rng.choice(data_U.shape[0], size=NUM_TO_EVAL, replace=False)\n",
    "t0 = rng.integers(low=0, high=T - 1, size=NUM_TO_EVAL)\n",
    "remaining = T - t0\n",
    "dt = rng.integers(low=0, high=remaining)\n",
    "tf = t0 + dt\n",
    "\n",
    "print(\"t0 indices:\", t0)\n",
    "print(\"tf indices:\", tf)\n",
    "assert np.all(tf < T), \"tf indices must be less than T\"\n",
    "assert np.all(t0 >= 0), \"t0 indices must be non-negative\"\n",
    "assert np.all(tf >= t0), \"tf indices must be greater than or equal t0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49860867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: (20, 2, 64, 64)\n",
      "labels shape: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "perm_data = np.permute_dims(data_U, (0, 4, 1, 2, 3)).squeeze()\n",
    "\n",
    "sample_data = np.stack([\n",
    "    perm_data[sample_idxs, t0, ...],\n",
    "    perm_data[sample_idxs, tf, ...],\n",
    "], axis=1)\n",
    "\n",
    "assert np.all(sample_data[:, 0, ...] == perm_data[sample_idxs, t0, ...]), \"A data is not matching!\"\n",
    "assert np.all(sample_data[:, 1, ...] == perm_data[sample_idxs, tf, ...]), \"U data is not matching!\"\n",
    "\n",
    "print(f\"samples shape: {sample_data.shape}\")  # (NUM_TO_EVAL, 2, S, S)\n",
    "\n",
    "sample_alphas = data_labels[sample_idxs, :]\n",
    "sample_tsteps = (t_steps[tf] - t_steps[t0])[:, np.newaxis]  # (NUM_TO_EVAL,)\n",
    "\n",
    "sample_labels = np.concatenate([sample_alphas, sample_tsteps], axis=1)  # (NUM_TO_EVAL, 2)\n",
    "print(f\"labels shape: {sample_labels.shape}\")  # (NUM_TO_EVAL, 2)\n",
    "\n",
    "data = torch.tensor(sample_data, dtype=torch.float32)\n",
    "labels = torch.tensor(sample_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_obj_fun(params, sampler, method, data, labels, batch_size, dx, num_steps):\n",
    "    N, C, H, W = data.shape\n",
    "    zeta_a = zeta_u = zeta_pde = None\n",
    "    if method == \"joint\":\n",
    "        zeta_a, zeta_u, zeta_pde = params\n",
    "    elif method == \"forward\":\n",
    "        zeta_u, zeta_pde = params\n",
    "\n",
    "    total_mse = 0.0\n",
    "    with sampling_context(sampler):\n",
    "        for i in tqdm(range(data.shape[0])):\n",
    "            mask_a, mask_u = generate_masks(\n",
    "                interior_a=interior_a,\n",
    "                interior_u=interior_u,\n",
    "                boundary_a=boundary_a,\n",
    "                boundary_u=boundary_u,\n",
    "                same_boundary=same_boundary,\n",
    "            )\n",
    "            obs_a = data[i, 0].expand(batch_size, 1, H, W) if method == \"joint\" else None\n",
    "            obs_u = data[i, 1].expand(batch_size, 1, H, W)\n",
    "            net_obs = data[i, 0].expand(batch_size, 1, H, W) if method == \"joint\" else None\n",
    "            lbls = labels[i].expand(batch_size, -1)\n",
    "\n",
    "            samples, losses = sampler.sample_conditional(\n",
    "                labels=lbls,\n",
    "                dx=dx,\n",
    "                net_obs=net_obs,\n",
    "                obs_a=obs_a,\n",
    "                obs_u=obs_u,\n",
    "                mask_a=mask_a,\n",
    "                mask_u=mask_u,\n",
    "                zeta_a=zeta_a,\n",
    "                zeta_u=zeta_u,\n",
    "                zeta_pde=zeta_pde,\n",
    "                num_steps=num_steps,\n",
    "                return_losses=False,\n",
    "            )\n",
    "\n",
    "            if method == \"joint\":\n",
    "                total_mse += torch.mean((samples - torch.stack([obs_a, obs_u], dim=0).unsqueeze(0))**2).item()\n",
    "            elif method == \"forward\":\n",
    "                total_mse += torch.mean((samples - obs_u.unsqueeze(0).unsqueeze(0))**2).item()\n",
    "            \n",
    "    return total_mse / N\n",
    "\n",
    "\n",
    "bounds = [\n",
    "    (100.0, 20000.0),   # bounds for zeta_a, comment out if method is \"forward\"\n",
    "    (100.0, 20000.0),   # bounds for zeta_u\n",
    "    (1.0, 100.0),    # bounds for zeta_pde\n",
    "]\n",
    "\n",
    "wrapper_kwargs = {\n",
    "    \"sampler\": sampler,\n",
    "    \"method\": run_cfg.dataset.method,\n",
    "    \"data\": data,\n",
    "    \"labels\": labels,\n",
    "    \"batch_size\": 16,\n",
    "    \"dx\": dx,\n",
    "    \"num_steps\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63284bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s204790/miniconda3/envs/dyndiffenv2/lib/python3.13/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 100.0, 1.0] before, using random point [12741.473718591596, 16728.777050800327, 5.686037379017396]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = gp_minimize(\n",
    "    func=lambda params: sampler_obj_fun(params, **wrapper_kwargs),\n",
    "    dimensions=bounds,\n",
    "    n_calls=30,\n",
    "    n_initial_points=10,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79ed056a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'fun', 'func_vals', 'x_iters', 'models', 'space', 'random_state', 'specs'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "360fab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [100.0, 13722.394220050628, 1.0]\n",
      "fun: 0.013466795653221198\n",
      "func_vals: [1.84583912e+01 1.47831648e+01 1.16305858e+01 1.46394261e+01\n",
      " 2.03273044e+01 1.46152473e+01 2.50619684e-01 7.88899866e-01\n",
      " 2.47976245e+00 1.96080255e+01 4.20600257e-02 1.45072287e-02\n",
      " 4.62257431e-02 1.45387571e-02 1.56014476e+01 5.06286515e-02\n",
      " 4.72320216e-02 1.34667957e-02 1.36177138e-02 2.27590450e-02\n",
      " 1.98527799e-02 3.96008874e-02 1.49996944e-02 6.21410084e+00\n",
      " 1.49611009e-02 1.67604788e-02 1.38789765e-02 1.38827184e-02\n",
      " 4.76937738e-02 9.17000175e+00]\n",
      "x_iters: [[15951.205438518638, 3750.35231833666, 78.18940902700417], [11977.318143135093, 8972.071781786466, 10.897516665982288], [9239.052950120758, 6740.801361666536, 15.14381497427214], [13052.680611682175, 1222.5904226392954, 72.47787845441566], [18777.198909413433, 115.49744023618514, 99.22894436983056], [12387.882041591562, 12271.897893716792, 1.6995642167520235], [558.9422583241736, 10543.015739141947, 40.5862361998103], [1028.646697950947, 19477.73482494504, 24.044362702600125], [1903.0680472031343, 12405.881585728439, 38.86373713544912], [19666.29462755509, 9388.581575634802, 86.13410026689576], [100.0, 100.0, 100.0], [100.0, 20000.0, 1.0], [100.0, 20000.0, 100.0], [100.0, 100.0, 1.0], [12741.473718591596, 16728.777050800327, 5.686037379017396], [100.0, 11985.713623976628, 100.0], [100.0, 10787.094886238152, 100.0], [100.0, 13722.394220050628, 1.0], [100.0, 13484.282730939738, 1.0], [184.63949399936763, 20000.0, 1.0], [100.0, 10703.700456584344, 41.54865730455071], [100.0, 100.0, 81.2547791659785], [143.84803944583797, 100.0, 1.0], [4371.440790175876, 2642.8373919849423, 3.8102633941509745], [100.0, 100.0, 10.747600100124588], [150.20217171781536, 100.0, 1.0], [100.0, 6250.84096718906, 1.0], [100.0, 6342.103269758137, 1.0], [247.21940896941712, 100.0, 1.0], [6506.650401212736, 15353.067960727933, 88.68825376525413]]\n",
      "models: [GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542)]\n",
      "space: Space([Real(low=100.0, high=20000.0, prior='uniform', transform='normalize'),\n",
      "       Real(low=100.0, high=20000.0, prior='uniform', transform='normalize'),\n",
      "       Real(low=1.0, high=100.0, prior='uniform', transform='normalize')])\n",
      "random_state: RandomState(MT19937)\n",
      "specs: {'args': {'func': <function <lambda> at 0x70034bf4a5c0>, 'dimensions': Space([Real(low=100.0, high=20000.0, prior='uniform', transform='normalize'),\n",
      "       Real(low=100.0, high=20000.0, prior='uniform', transform='normalize'),\n",
      "       Real(low=1.0, high=100.0, prior='uniform', transform='normalize')]), 'base_estimator': GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5),\n",
      "                         n_restarts_optimizer=2, noise='gaussian',\n",
      "                         normalize_y=True, random_state=1608637542), 'n_calls': 30, 'n_random_starts': None, 'n_initial_points': 10, 'initial_point_generator': 'random', 'acq_func': 'gp_hedge', 'acq_optimizer': 'auto', 'x0': None, 'y0': None, 'random_state': RandomState(MT19937) at 0x7005690B1640, 'verbose': False, 'callback': None, 'n_points': 10000, 'n_restarts_optimizer': 5, 'xi': 0.01, 'kappa': 1.96, 'n_jobs': 1, 'model_queue_size': None, 'space_constraint': None}, 'function': 'base_minimize'}\n"
     ]
    }
   ],
   "source": [
    "for k, v in res.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062930d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyndiffenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
