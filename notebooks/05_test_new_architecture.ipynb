{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b29ece90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import diffusion_pde as dpde\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e815685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet2(\n",
      "  (down_blocks): ModuleDict(\n",
      "    (down_2->32_down): UnetBlock(\n",
      "      (conv1): Conv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(2, 2, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (down_32->64_down): UnetBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (down_64->128_down): UnetBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=128, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (down_128->256_): UnetBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=256, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (up_blocks): ModuleDict(\n",
      "    (up_256->128_): UnetBlock(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=128, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (up_128->64_up): UnetBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up_64->32_up): UnetBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up_32->1_up): UnetBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (emb_layer): Linear(in_features=32, out_features=1, bias=True)\n",
      "      (act_fn): SiLU()\n",
      "      (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (norm2): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (skip): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sigma_embedding): PositionalEmbedding()\n",
      "  (linear_label): Linear(in_features=2, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_channels, max_positions=10000, endpoint=False):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.max_positions = max_positions\n",
    "        self.endpoint = endpoint\n",
    "\n",
    "    def forward(self, x):\n",
    "        freqs = torch.arange(start=0, end=self.num_channels//2, dtype=torch.float32, device=x.device)\n",
    "        freqs = freqs / (self.num_channels // 2 - (1 if self.endpoint else 0))\n",
    "        freqs = (1 / self.max_positions) ** freqs\n",
    "        x = x.ger(freqs.to(x.dtype))\n",
    "        x = torch.cat([x.cos(), x.sin()], dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UnetBlock(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        in_ch: int, \n",
    "        out_ch: int, \n",
    "        emb_ch: int, \n",
    "        mode =\"\", \n",
    "        act_fn: torch.nn.Module = torch.nn.SiLU, \n",
    "        dropout: float = 0.1,\n",
    "        skip_scale: float = 2**-0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.skip_scale = skip_scale\n",
    "\n",
    "        if mode == \"down\":\n",
    "            self.conv1 = torch.nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1)\n",
    "        elif mode == \"\":\n",
    "            self.conv1 = torch.nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        elif mode == \"up\":\n",
    "            self.conv1 = torch.nn.Sequential(\n",
    "                torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                torch.nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "            )\n",
    "            #self.conv1 = torch.nn.ConvTranspose2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        torch.nn.init.zeros_(self.conv2.weight)\n",
    "        torch.nn.init.zeros_(self.conv2.bias)\n",
    "\n",
    "        self.emb_layer = torch.nn.Linear(emb_ch, out_ch)\n",
    "        self.act_fn = act_fn()\n",
    "\n",
    "        self.norm1 = torch.nn.GroupNorm(32 if in_ch % 32 == 0 else in_ch, in_ch)\n",
    "        self.norm2 = torch.nn.GroupNorm(32 if out_ch % 32 == 0 else out_ch, out_ch)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        if mode == \"\" and in_ch == out_ch:\n",
    "            self.skip = torch.nn.Identity()\n",
    "        elif mode == \"down\":\n",
    "            self.skip = torch.nn.Sequential(\n",
    "                torch.nn.AvgPool2d(2),\n",
    "                torch.nn.Conv2d(in_ch, out_ch, kernel_size=1) if in_ch != out_ch else torch.nn.Identity()\n",
    "            )\n",
    "        elif mode == \"up\":\n",
    "            self.skip = torch.nn.Sequential(\n",
    "                torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                torch.nn.Conv2d(in_ch, out_ch, kernel_size=1) if in_ch != out_ch else torch.nn.Identity(),\n",
    "            )\n",
    "        else:\n",
    "            self.skip = torch.nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, emb: torch.Tensor) -> torch.Tensor:\n",
    "        orig = x\n",
    "        emb = self.emb_layer(emb).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x = self.conv1(self.act_fn(self.norm1(x)))\n",
    "        x = x + emb\n",
    "        x = self.conv2(self.dropout(self.act_fn(self.norm2(x))))\n",
    "        x = x + self.skip(orig)\n",
    "\n",
    "        return x * self.skip_scale\n",
    "    \n",
    "    \n",
    "class Unet2(torch.nn.Module):\n",
    "    '''\n",
    "    Unet taken from deep learning course.\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        chs: list[int], # list of channels including input channel size: (ch_in, ch_1, ..., ch_n), length n+1\n",
    "        label_ch: int, # label dimension (class label/ time etc)\n",
    "        noise_ch: int = 32, # embedding channel size \n",
    "        act_fn: torch.nn.Module = torch.nn.SiLU,\n",
    "        debug: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act_fn = act_fn\n",
    "        self.debug = debug\n",
    "\n",
    "        self.down_blocks = torch.nn.ModuleDict()\n",
    "        self.up_blocks = torch.nn.ModuleDict()\n",
    "\n",
    "        # create encoder blocks \n",
    "        for i in range(len(chs)-1):\n",
    "            mode = \"down\" if i < len(chs)-2 else \"\"\n",
    "            in_ch = chs[i] * 2 if i == 0 else chs[i]\n",
    "            out_ch = chs[i+1]\n",
    "            self.down_blocks[f\"down_{in_ch}->{out_ch}_{mode}\"] = UnetBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=chs[i+1],\n",
    "                emb_ch=noise_ch,\n",
    "                mode=mode,\n",
    "                act_fn=act_fn,\n",
    "            )\n",
    "        \n",
    "\n",
    "        # create decoder blocks\n",
    "        for i in range(len(chs)-1, 0, -1):\n",
    "            mode = \"up\" if i < len(chs)-1 else \"\"\n",
    "            in_ch = chs[i] * 2 if i < len(chs)-1 else chs[i]\n",
    "            out_ch = chs[i-1]\n",
    "            self.up_blocks[f\"up_{chs[i]}->{chs[i-1]}_{mode}\"] = UnetBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                emb_ch=noise_ch,\n",
    "                mode=mode,\n",
    "                act_fn=act_fn,\n",
    "            )\n",
    "\n",
    "\n",
    "        self.sigma_embedding = PositionalEmbedding(noise_ch)\n",
    "        self.linear_label = torch.nn.Linear(label_ch, noise_ch)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x, sigma, labels, obs) -> torch.Tensor:\n",
    "        x = torch.cat([x, obs], dim=1)  # concatenate input and observation along channel dimension\n",
    "        emb_sigma = self.sigma_embedding(sigma)\n",
    "        emb_label = self.linear_label(labels)\n",
    "\n",
    "        skips = []\n",
    "        for i, down_block in enumerate(self.down_blocks.values()):\n",
    "            x = down_block(x, emb_sigma + emb_label)\n",
    "            if i < len(self.down_blocks) - 1:\n",
    "                skips.append(x)\n",
    "                if self.debug:\n",
    "                    print(f\"Skip Block {i}: {x.shape}\")\n",
    "            if self.debug:\n",
    "                print(f\"Down Block {i}: {x.shape}\")\n",
    "\n",
    "        for i, up_block in enumerate(self.up_blocks.values()):\n",
    "            if i > 0:\n",
    "                skip = skips.pop()\n",
    "                if self.debug:\n",
    "                    print(f\"Using Skip Block {len(self.down_blocks)-2 - i}: {skip.shape}\")\n",
    "                x = torch.cat([x, skip], dim=1)\n",
    "            x = up_block(x, emb_sigma + emb_label)\n",
    "            if self.debug:\n",
    "                print(f\"Up Block {i}: {x.shape}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "chs = [1, 32, 64, 128, 256]\n",
    "label_ch = 2\n",
    "noise_ch = 32\n",
    "net = Unet2(chs=chs, label_ch=label_ch, noise_ch=noise_ch, debug=False)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3e87ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([10, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.randn(10, 1, 64, 64)\n",
    "test_sigma = torch.randn(10)\n",
    "test_labels = torch.randn(10, 2)\n",
    "test_obs = torch.randn(10, 1, 64, 64)\n",
    "\n",
    "out = net(test_x, test_sigma, test_labels, test_obs)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ae610b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDMWrapper(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        unet: torch.nn.Module,\n",
    "        sigma_data: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "        self.sigma_data = sigma_data\n",
    "\n",
    "    def forward(self, x, sigma, *args) -> torch.Tensor:\n",
    "        # x has shape (b, ch, h, w) and sigma has shape (b,)\n",
    "        # both should be dtype float32 for now\n",
    "        sigma = torch.reshape(sigma, (-1, 1, 1, 1))\n",
    "\n",
    "        # weights given by the EDM paper.\n",
    "        c_skip = self.sigma_data ** 2 / (sigma ** 2 + self.sigma_data ** 2)\n",
    "        c_out = sigma * self.sigma_data / torch.sqrt(sigma ** 2 + self.sigma_data ** 2)\n",
    "        c_in = 1 / torch.sqrt(sigma ** 2 + self.sigma_data ** 2)\n",
    "        c_noise = torch.flatten(torch.log(sigma) / 4).to(torch.float32)\n",
    "\n",
    "        F_x = self.unet(c_in * x, c_noise, *args)   # output of u-net\n",
    "        D_x = c_skip * x + c_out * F_x          # denoised data\n",
    "\n",
    "        return D_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6976d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "edm = EDMWrapper(net, sigma_data=0.5)\n",
    "out = edm(test_x, test_sigma, test_labels, test_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19f63063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionDataset2(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Diffusion dataset compatible with torch DataLoader.\n",
    "    Each item is a tuple (X, label) where X is the concatenation of the\n",
    "    initial state and a snapshot of the trajectory at time t. the label\n",
    "    is a vector containing the time t and any additional labels.\n",
    "    Note that t is sampled randomly for each item from the t_steps provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : torch.Tensor\n",
    "        Tensor of shape (N, ch_u, h, w, T) representing the trajectories.\n",
    "    t_steps : torch.Tensor\n",
    "        1D tensor of shape (T,) representing the time steps corresponding to the last dimension of `data`.\n",
    "    labels : Optional[torch.Tensor], optional\n",
    "        Optional tensor of shape (N, label_dim) representing additional labels, by default None.\n",
    "    generator : Optional[torch.Generator], optional\n",
    "        Random number generator for reproducibility, by default None.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        data: np.ndarray, \n",
    "        t_steps: np.ndarray, \n",
    "        labels: np.ndarray | None = None,\n",
    "        generator: torch.Generator | None = None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # assume data is (N, ch_u, h, w, t)\n",
    "        assert len(data.shape) == 5, f\"Dimensions of 'data' should be (N, ch_u, h, w, t) but got {data.shape}\"\n",
    "\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.labels = torch.from_numpy(labels).float() if labels is not None else None\n",
    "        if self.labels is not None and self.labels.ndim == 1:\n",
    "            self.labels = self.labels.reshape((-1, 1))  # ensure labels is (N, label_dim):\n",
    "        self.t_steps = torch.from_numpy(t_steps).float()\n",
    "\n",
    "        self.N, self.T = data.shape[0], data.shape[-1]\n",
    "\n",
    "        self.g = generator\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # sample random timestep\n",
    "        t0_idx = torch.randint(0, self.T-1, (1,), generator=self.g).item()\n",
    "        tf_idx = torch.randint(t0_idx + 1, self.T, (1,), generator=self.g).item()\n",
    "\n",
    "        # slice data snapshot at timestep\n",
    "        # get corresponding time value\n",
    "        X = self.data[idx, ..., t0_idx]  # shape (ch_u, h, w)\n",
    "        Y = self.data[idx, ..., tf_idx]  # shape (ch_u, h, w)\n",
    "        label = self.t_steps[tf_idx] - self.t_steps[t0_idx]  # time difference as label\n",
    "        if self.labels is not None:\n",
    "            label = torch.cat((torch.tensor([label]), self.labels[idx]), dim=0)\n",
    "        return X, Y, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "62f204db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDMLoss:\n",
    "    '''\n",
    "    taken from \"elucidating the design space...\" paper:\n",
    "    https://github.com/NVlabs/edm/blob/main/training/loss.py\n",
    "    '''\n",
    "    def __init__(self, P_mean=-1.2, P_std=1.2, sigma_data=0.5, reduce=True, reduce_method=\"mean\"):\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.sigma_data = sigma_data\n",
    "        self.reduce = reduce\n",
    "        self.reduce_method = reduce_method\n",
    "\n",
    "    def __call__(self, net, x, *args):\n",
    "        rnd_normal = torch.randn([x.shape[0], 1, 1, 1], device=x.device)\n",
    "        sigma = (rnd_normal * self.P_std + self.P_mean).exp()\n",
    "        weight = (sigma ** 2 + self.sigma_data ** 2) / (sigma * self.sigma_data) ** 2\n",
    "        n = torch.randn_like(x) * sigma\n",
    "        D_yn = net(x + n, sigma.flatten(), *args)\n",
    "        loss = weight * ((D_yn - x) ** 2)\n",
    "\n",
    "        if not self.reduce:\n",
    "            return loss\n",
    "\n",
    "        if self.reduce_method == \"mean\":\n",
    "            return loss.mean(dim=(1,2,3))\n",
    "        elif self.reduce_method == \"sum\":\n",
    "            return loss.sum(dim=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e3d44f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/s204790/dynamical-pde-diffusion/data/heat_logt.hdf5\")\n",
    "\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    data = f[\"U\"][:]\n",
    "    t_steps = f[\"t_steps\"][:]\n",
    "    labels = f[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2413a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiffusionDataset2(data=data, t_steps=t_steps, labels=labels)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ab89a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "edm = edm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99f0b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1969491\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ccedd85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 4.7524\n",
      "Epoch 10/100, Loss: 2.5002\n",
      "Epoch 15/100, Loss: 3.9297\n",
      "Epoch 20/100, Loss: 3.1842\n",
      "Epoch 25/100, Loss: 2.2436\n",
      "Epoch 30/100, Loss: 2.0965\n",
      "Epoch 35/100, Loss: 2.2918\n",
      "Epoch 40/100, Loss: 2.2818\n",
      "Epoch 45/100, Loss: 2.0736\n",
      "Epoch 50/100, Loss: 1.6578\n",
      "Epoch 55/100, Loss: 1.7171\n",
      "Epoch 60/100, Loss: 1.5671\n",
      "Epoch 65/100, Loss: 1.5321\n",
      "Epoch 70/100, Loss: 1.7482\n",
      "Epoch 75/100, Loss: 1.3385\n",
      "Epoch 80/100, Loss: 1.5424\n",
      "Epoch 85/100, Loss: 1.4815\n",
      "Epoch 90/100, Loss: 1.4001\n",
      "Epoch 95/100, Loss: 0.8724\n",
      "Epoch 100/100, Loss: 0.9480\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "print_every = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(edm.parameters(), lr=1e-4)\n",
    "loss_fn = EDMLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for (X, Y, labels) in dataloader:\n",
    "        X, Y, labels = X.to(device), Y.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(edm, Y, labels, X).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % print_every == print_every - 1:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a4916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyndiffenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
